 \item \textbf{Zero-Knowledge Proofs and Sigma Protocols:} Fiat-Shamir introduced practical zero-knowledge protocols \textbf{CITE Fiat Shamir}, Schnorr's identification protocol build the foundation of sigma protocols over the discrete logarithm relations \cite{brands1996privacy, goos_rapid_1997, brands_rethinking_2000} and Camenisch-Stadler formalized proofs of knowledge for group homomorphism which is the building block for proving discrete log relations in commitment schemes \cite{goos_efficient_1997} and damgards work on sigma protocols \cite{damgard_sigma_2010}.

    \item \textbf{Pairing-based Signatures: } Boneh-Lynn-Shacham (BLS) \cite{goos_short_2001} introduced the first short signature using bilinear pairings, Boneh-Boyen-Shacham (BBS) \cite{hutchison_short_2004} showed how to sign committed messages, Camenisch-Lysyanskaya \cite{cimato_signature_2003, hutchison_signature_2004} demonstrated how pairings enable signature randomization.

    \item \textbf{Commitments: } \cite{pedersen1991non} Pedersen introduced his commitment scheme with perfect hiding and computational binding under the discrete log, \cite{goos_efficient_1997} Camenisch-Stadler formalized the ntoationa dn composition of sigma protocols over commitments and due to their algebraic compatibility with pairing based signatures, pedersen commitments were integrated in the early BLS, BBS, CL signatures \cite{goos_short_2001, hutchison_short_2004, hutchison_signature_2004}. 
    



% Take advantage of how they discuss the project here, including security properties, actors, etc
% https://eprint.iacr.org/2023/1218.pdf

% Tikz people
% https://texdoc.org/serve/tikzpeople/0


% DECO style credential oracles

% [24] Sofía Celi, Alex Davidson, Hamed Haddadi, Gonçalo Pestana, and Joe Rowell. 2023. Distefano: Decentralized infrastructure for sharing trusted encrypted facts and nothing more. ePrint Archive.
% [25] Kwan Yin Chan, Handong Cui, and Tsz Hon Yuen. 2023. DIDO: Data Provenance from Restricted TLS 1.3 Websites. ePrint (2023).
% [54] Jan Lauinger, Jens Ernstberger, Andreas Finkenzeller, and Sebastian Steinhorst. 2023. Janus: Fast Privacy-Preserving Data Provenance For TLS 1.3. ePrint (2023).
% [81] Xiang Xie, Kang Yang, Xiao Wang, and Yu Yu. 2023. Lightweight Authentication of Web Data via Garble-Then-Prove. ePrint (2023).


\section{Appendix, Old Writings}
\newpage


\subsection{Zero Knowledge Proof}
\begin{itemize}
    \item $ZKP.ComOpen_{ck}(cm, m_i, r) \to \Pi^{cm}$
    \item $ZKP.ComOpenVfy_{ck}(cm, \Pi^{cm}) \to \bit$
\end{itemize}

\subsection{Anonymous Credential}


\begin{center}
\begin{tabular}{l@{\hspace{8em}}c@{\hspace{8em}}l}
\multicolumn{3}{l}{$\underline{OrgKeyGen(1^{\lambda}, 1^n)}$:  Given $\lambda, n > 0$, compute $BG = (p, \G_1, \G_2, \G_T, e, g, \tilg) $}.\\[0.5em]
\multicolumn{3}{l}{Run $ck \gets CM.Setup(BG, 1^{\lambda}, 1^n)$ which defines $(g, g^{\yb}, \tilg, \tilg^{\yb})$ with $ \yb_{\in[n]}$} \\[0.5em]
\multicolumn{3}{l}{Run $(sk, vk) \gets PS.KeyGen(ck, 1^{\lambda}, 1^n)$ which defines $sk = X \in \G_1$ and $vk = \tilx \in \G_2$}\\[0.5em]
\multicolumn{3}{l}{$osk = (g, X), opk = (ck, \tilx, BG)$, return $(osk, opk)$}\\[2em]
\underline{Obtain(opk, $\mathbf{m}$)} && \underline{Issue(osk, $cm$)} \\[1em]
\multicolumn{3}{l}{Parse $opk = (ck, \tilx, BG)$, sample $r \sample \Z_p$} \\[0.5em]
\multicolumn{3}{l}{Compute $(cm, \widehat{cm}) \gets CM.Com(ck, \mathbf{m}, r)$} \\[0.5em]
\multicolumn{3}{l}{Run $\Pi^{cm} \gets ZKP.ComOpen(ck, cm, \mathbf{m}, r)$} \\[0.5em]
& $\xrightarrow{\Pi^{cm}}$ & \\[1em]
\multicolumn{3}{r}{If $ZKP.ComOpenVfy(\Pi^{cm},cm) = 0$, return $\bot$} \\[1em]
& $\xleftarrow{\sigma = (\sigma_1, \sigma_2)}$ & $\sigma \gets \mathsf{PS.Sign}(osk, cm)$ \\[1em]
\multicolumn{3}{l}{If $\mathsf{PS.Verify}(opk, cm, \sigma) = 0$, return $\bot$} \\[1em]
\multicolumn{3}{l}{$Cred \gets (\sigma = (\sigma_1, \sigma_2), opk, cm, \widehat{cm})$} \\[1em]
\end{tabular}
\end{center}

\noindent \underline{(Show, Verify)}: Using ..... Show, and Verify interact as follows



\begin{center}
    \begin{tabular}{l@{\hspace{8em}}c@{\hspace{8em}}l}
    \underline{Show($opk, cm, Cred$)} && \underline{Verify($osk, Cred' $)} \\[1em]
    \end{tabular}
\end{center}

\subsection{Old Intro}

\textbf{Privately Linked Context Credentials}
The Internet Identity Workshop discussed a problem space summarised by the following problems:
1. issuing credentials that are both government and privately issued
2. retaining accountability in derived credentials, ensuring derived credentials are fit for purpose and have revocation (Proveable Provenance, Linked Data)
3. combining traditional digital identity with decentralized identity




As digital wallets are gradually introduced, one notable problem involves combining 
As digital identities are introduced, there must be methods to combine the old world and the new world with respect to identities. 
One problem use-case is organisations such as a university issuing certificates as credentials. 
Universities want to start issuing credentials to users 

A university, a credential provider, and wants to issue a credential to a user sam.

The University is not yet using decentralized identity but would like to issue a credential to Sam's digital identity wallet. 
Sam's logged in to the university portal with his classical login. Sam presses "Issue Credential" and starts the credential-issuing process. 

The university wants to check a few things before issuing this credential.
1. make sure their national credential is valid, that is, it verifies
2. as it's an anonymous credential, the university wants to make sure the user that's logged into their portal is the same user with the registration credential. The user may selectively disclose their attributes, or prove equality of attributes in zero knowledge, or may have another proof.

The university generates a credentialId and stores it in their system and carries out the following protocol with Sam

Sam wants to keep as many details as secret as possible, and thus, he carries out the following protocol
1. Sam creates a new commitment Com([pid, 0]r), proves opening of the commitment and equality of pid between rcm and this commitment.
2. The university generates Com([0,credId]0) and homomorphically creates ccm([pid, credId]r) = Com([pid, 0]r) x Com([0,credId]0). The university then signs ccm([pid, credId]r) with their own signature scheme.
3. Sam can now take rcm and ccm, sigma(ccm) to the blockchain of nodes.
4. Sam runs a protocol with the blockchain to be issued a Decentralied version of this credential with full private accountability. 


\subsection{ZKP Sigma Protocol for proving PRF output with pairing}

\[
ZKP
    \left\{ 
    (m_1, m_2, r_1, r_2): C_1 = g_1^{m_1}h_1^{r_1} \in \G_1 \wedge C_2 = g_2^{m_2}h_2^{r_2} \in \G_2 \wedge m_1 \cdot m_2 = 1
    \right\}
\]


\pcb{
\prover[m_1, m_2, r_1, r_2] \< \< \verifier[C_1, C_2, g, h]  \\[0.1\baselineskip][\hline]
\<\< \\[-0.5\baselineskip]
\pclinecomment{$C_1 = g_1^{m_1}h_1^{r_1}, C_2 = g_2^{m_2}h_2^{r_2}$ } \\
{\{\rho_i\}_{i=1}^2, \{\beta_i\}_{i=1}^2, \{\gamma_i\}_{i=1}^4}  \sample \mathbb{Z}_q^8 \<\< \\
T_1 \in \G_1 \gets g_1^{\beta_1}h_1^{\rho_1} \<\< \\
T_2 \in \G_2 \gets g_2^{\beta_2}h_2^{\rho_2} \<\< \\
\pclinecomment{generate interim elements} \\
\alpha_1 \gets m_1 \cdot m_2 \<\< \\
\alpha_2 \gets m_1 \cdot t_2 \<\< \\
\alpha_3 \gets t_1 \cdot m_2 \<\< \\
\alpha_4 \gets t_1 \cdot t_2 \<\< \\
A_1 \gets e(g_1, g_2) \<\< \\
A_2 \gets e(g_1, h_2) \<\< \\
A_3 \gets e(h_1, g_2) \<\< \\
A_4 \gets e(h_1, h_2) \<\< \\
\pclinecomment{$C_3 = e(C_1, C_2)$} \\
C_3 \in \G_T \gets A_1^{\alpha_1} A_2^{\alpha_2} A_3^{\alpha_3}  A_4^{\alpha_4}\<\< \\
T_3 \in \G_T \gets  A_1^{\gamma_1} A_2^{\gamma_2} A_3^{\gamma_3} A_4^{\gamma_4} \<\< \\
\< \sendmessageright* {\{C_i, T_i\}_{i=1}^3, \{A_i\}_{i=1}^4} \< \\
\< \sendmessageleft*{e} \< e \sample \mathbb{Z}_q \\
\{z_{mi} = \beta_i + e \cdot m_i \}_{i=1}^2 \<\< \\
\{z_{ri} = \rho_i + e \cdot r_i \}_{i=1}^2 \<\< \\
\{z_{ai} = \gamma_i + e \cdot \alpha_i \}_{i=1}^4 \<\< \\
\< \sendmessageright*{\{z_{mi}, z_{ri}\}_{i=1}^2, \{z_{ai}\}_{i=1}^4 } \< \\
\<\< C_1^e \cdot T_1 \stackrel{?}{=} g_1^{z_{m1}} h_1^{z_{r1}}\\
\<\< C_2^e \cdot T_2 \stackrel{?}{=}  g_2^{z_{m2}} h_2^{z_{r2}}\\
\<\< C_3^e \cdot T_3 \stackrel{?}{=}  A_1^{z_{a1}}A_2^{z_{a2}}A_3^{z_{a3}}A_4^{z_{a4}}\\
\<\< 
}


\newpage
\subsubsection{Completeness}
Proof of knowledge of exponents $m1, r1$ by opening $C_1$
    \begin{align}
    C_1^e \cdot T_1 &\stackrel{?}{=} g^{z_{m1}} h^{z_{r1}} \notag \\
    (g^{m1}h^{r_1})^e \cdot g^{\beta_1}h^{\rho_1} &= g^{\beta_1 + e \cdot m_1} h^{\rho_1 + e \cdot r_1} \notag \\
    g^{e \cdot m1 + \beta_1}h^{e \cdot r_1 + \rho_1} &= g^{\beta_1 + e \cdot m_1} h^{\rho_1 + e \cdot r_1} \notag
    \end{align}

    
Proof of knowledge of exponents $m2, r2$ by opening $C_2$
\begin{align}
    C_2^e \cdot T_2 &\stackrel{?}{=} \tilg^{z_{m2}} \tilh^{z_{r2}} && \label{eq:ver2} \\
    (\tilg^{m2}\tilh^{r_2})^e \cdot \tilg^{\beta_2}\tilh^{\rho_2} &= \tilg^{\beta_2 + e \cdot m_2} \tilh^{\rho_2 + e \cdot r_2} \notag \\
    \tilg^{e \cdot m2 + \beta_2}\tilh^{e \cdot r_2 + \rho_2} &= \tilg^{\beta_2 + e \cdot m_2} \tilh^{\rho_2 + e \cdot r_2} \notag
    \end{align}

    
\begin{align}
    C_3 = e(C_1, \tilde{C_2}) = e(g^{m1} h^{r1}, \tilg^{m2} \tilh^{r2}) \notag \\
    = e(g^{m1}, \tilg^{m2}) \cdot e(g^{m1},\tilh^{r2}) \cdot e(h^{r1}, g^{m2}) \cdot e(h_1^{r1}, \tilh^{r2})  \notag \\
    = e(g, \tilg)^{m1\cdot m2} \cdot e(g,\tilh)^{m1 \cdot r2} \cdot e(h, \tilg)^{r1 \cdot m2} \cdot e(h, \tilh)^{r1 \cdot r2}  \notag \\
\end{align}



\begin{itemize}
    \item Prove knowledge of exponents $(m1 \cdot r2), (r1 \cdot m2), (r1 \cdot r2)$ for $C_3$/$e(g,\tilg)$  with respect to base points $e(g,\tilh) e(h, \tilg) e(h, \tilh)$
    \item $C_3$/$e(g,\tilg)$ 
    \item 
\end{itemize}


Prove that $e(g, \tilg)^{(m1 \cdot m2)} = e(g, \tilg)$ by computing $C_4 = e(g,\tilh)^{m1 \cdot r2} \cdot e(h, \tilg)^{r1 \cdot m2} \cdot e(h, \tilh)^{r1 \cdot r2}$, proving the opening and equality of $(m1 \cdot r2), (r1 \cdot m2), (r1 \cdot r2)$ with $C_3$, then proving $C_3/C_4 = e(g, \tilg) \cdot e(g,\tilh) \cdot e(h, \tilg) \cdot e(h, \tilh) $

\newpage
\subsubsection{Analysis Pairing Method}
\begin{itemize}
    \item \textbf{Prover:} 2 $\G_1$ exp, 2 $\G_2$ exp, 8 $\G_T$ exp, 1 $\G_1$ add, 1 $\G_2$ add, 6 $\G_T$ mul, 12 $\F_p$ mul, 8 $\F_p$ add, 4 pairing
    
    \item \textbf{Verifier:} 3 $\G_1$ exp, 3 $\G_2$ exp, 5 $\G_T$ exp, 2 $\G_1$ add, 2 $\G_2$ add, 4 $\G_T$ mul
\end{itemize}

\subsubsection{Soundness}
\todonote{Sam todo}

\subsubsection{Zero Knowledge}
\todonote{Sam todo}



\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Operation} & \textbf{Prover} & \textbf{Verifier} \\
\hline
\multicolumn{3}{|l|}{\textbf{Commitment Equality Method}} \\
\hline
G1 exponentiations & 4 & 5 \\
G1 additions & 2 & 4 \\
Fp multiplications & 3 & 0 \\
Fp additions & 3 & 0 \\
\hline
\multicolumn{3}{|l|}{\textbf{G1 VRF Method}} \\
\hline
G1 exponentiations & 11 & 11 \\
G1 additions & 4 & 7 \\
Fp multiplications & 6 & 0 \\
Fp additions & 6 & 0 \\
\hline
\multicolumn{3}{|l|}{\textbf{Pairing + VRF Method}} \\
\hline
G1 exponentiations & 2 & 3 \\
G2 exponentiations & 2 & 3 \\
G1 additions & 1 & 2 \\
G2 additions & 1 & 2 \\
Fp multiplications & 12 & 0 \\
Fp additions & 8 & 0 \\
GT exponentiations & 8 & 5 \\
GT multiplications & 6 & 4 \\
Pairings & 4 & 4 \\
\hline
\end{tabular}
\caption{Comparison of computational operations between G1 and Pairing methods}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|l|r|}
\hline
\textbf{Operation} & \textbf{Time} \\
\hline
Full Pairing & 1.6218 ms \\
Miller Loop & 0.6931 ms \\
Final Exponentiation & 0.9287 ms \\
G1 Mixed Addition (Affine + Jacobian) & 672 ns \\
G1 Point Doubling (2P) & 414 ns \\
G2 Mixed Addition (Affine + Jacobian) & 2143 ns \\
G2 Point Doubling (2P) & 1302 ns \\
\hline
Estimated G1 Scalar Mult (255-bit) & 191.59 $\mu$s \\
\emph{\small(255 doublings + ~128 additions)} & \\
Estimated G2 Scalar Mult (255-bit) & 606.01 $\mu$s \\
\emph{\small(255 doublings + ~128 additions)} & \\
\hline
\end{tabular}
\caption{Performance metrics for arkworks BLS12-381 implementation. Scalar multiplication estimates assume naive double-and-add implementation without optimizations.}
\label{tab:arkworks-performance}
\end{table}
\footnotetext{The G1 and G2 scalar multiplication estimates are derived using a naive double-and-add implementation analysis for 255-bit scalars. For a random scalar $k$, we assume approximately 255 doubling operations (one per bit) and 128 addition operations (corresponding to an expected Hamming weight of $\frac{255}{2}$ for a random scalar). The G1 estimate of 191.59$\mu$s is computed as $(255 \times 414\text{ns}) + (128 \times 672\text{ns})$ using the measured doubling and mixed addition timings. Similarly, the G2 estimate of 606.01$\mu$s is computed as $(255 \times 1302\text{ns}) + (128 \times 2143\text{ns})$. These estimates represent upper bounds as they do not account for common optimizations such as windowing methods, NAF (Non-Adjacent Form) representations, or parallel computation strategies.}


\newpage
\subsection{Research Questions}
\textbf{Main Research Question: }

\textit{How can credential systems be designed to maintain accountability and sybil resistance with privacy and unlinkability. }

\noindent \textbf{Sub Research Questions}

\textit{How can we design a privacy-preserving credential system that enables hidden linking of government and private credentials while maintaining provable provenance and revocability?}

\textit{How can we efficiently combine credentials for verification while retaining their security properties}


\subsection{Methods}

\subsubsection{Notation}
Let $a : \N \mapsto \N \bigcup \{*\}$ and $b : \N \mapsto \N$ be any functions for which $a(\lambda)$ and $b(\lambda)$ are computable in $poly(\lambda)$ time (expect when $a$ takes value $*$).
\begin{definition}
    A function family $F_{(\cdot)}(\cdot) : \bit^{a(\lambda)} \mapsto \bit^{b(\lambda)}$ is a family of $VRFs$ if there exists a PPT algorithm $Gen$ and deterministic algorithms $Prove$ and $Ver$ such that $Gen(\secparam)$ outputs a pair of keys $(sk, pk)$, $Prove_{sk}(x)$ computes $(y, \pi)$ where $\pi$ is the proof of correctness, and $Ver_{pk}(x,y,\pi)$ verifies that $y = e(g,g)^{1/x+sk}$ using the proof $\pi = g^{1/x+sk}$
\end{definition}

\subsubsection{Notation - another version}
A probabilistic polynomial time algorithm $\algo(\ins) \rightarrow \out$ receives an input $\ins$ and returns an output $\out$. $r \getsrand \Zp$ r is sampled uniformly from the set of field elements modulo $p$,  $h \gets y$ is a deterministic assignment. $[n]$ denotes a sample space of $\{1,\dots,n\}$. We assume type 3 bilinear pairings, $e: \G_1 \times \G_2 \to \G_t$ over groups of prime order $p$, $g, \tilde{g}$ are uniformly chosen generators for $\G_1, \G_2$ such that $e(g, \tilde{g}) = g_t$. We use bold variables to denote vectors as \vect{m} = $[m_1, \dots, m_{\ell}]$, \textbf{g} $\in \G^{\ell}$, \textbf{x} $\in \Z_p^{\ell}$, $\textbf{g}^{\textbf{x}}$ = $\sum\nolimits_{i=1}^\ell g_i^{x_i}$. We use multiplicative notation for $\G$ points i.e. $g^k = g \cdot g \;  (k \text{ times})$

\subsubsection{Pseudo Random Function}
We use the properties of a pseudo-random function to derive the relationship between a master and context credential. The pseudorandomness property ensures the output $y$ is computationally indistinguishable from random and thus hides the relationship between the user's secret key $sk$ and an input $x$ which could be the context of the new credential we want to privately link to.
\[
    PRF_{sk}(x) \to y
\]

\begin{definition}[Pseudo Random Function]
    A PRF is a couple of algorithms $(PRF.Gen, f)$ with key space $\setK$, input space $\setX$ and output space $\setY$ such that 
    \begin{itemize}
        \item $Gen(\secparam) \to (sk): s \sample S$, sets $sk = s$
        \item $f:$ $\mathcal{K} \times \mathcal{X} \to \mathcal{Y}$ is a keyed function family
    \end{itemize}
\end{definition}

The main security property of a $PRF$ is pseudorandomness, which informally states the output should appear random and not be able to be guessed. Formally, defined as

\begin{definition}[Pseudorandomness]
    A couple of PPT algorithms $(PRF.Gen, f)$ is a \textit{Pseudo Random Function} if, for any $\PPT$ adversary $\adv$ there exists a negligible function $\epsilon$ such that 
    \[
    \advantage{}{}[(\adv)] := 
        \left|
    \Pr     \left[ 
                \mathsf{Exp}^{\mathsf{prf}}(\adv) = 1
            \right] - \frac{1}{2}
        \right| \leq \epsilon(\lambda)
    \]
\end{definition}

\begin{figure}
\begin{pchstack}[boxed, center, space=1em]
    \procedure[]{$\mathrm{Exp}^{\mathsf{prf}}(\adv)$}{%
        b \sample \bit \\
        \text{Sample } k \sample PRF.Gen(1^{\lambda}) \\
        \text{Sample } f^* \sample \{g : g : \mathcal{X} \to \mathcal{Y}\} \\
        \text{Run } b' \gets \adv^{\oracle_{\mathsf{prf}}}(1^{\lambda}) \\
        \pcreturn b == b'
    }
    \procedure[]{$\oracle_{\mathsf{prf}(x)}$}{%
        \pcif b = 1 \\
        \t \pcreturn f_k(x) \\
        \pcelse \\
        \t \pcreturn f^*(x)
    }
\end{pchstack}
  \caption{The pseudorandomness game with adversary $\adv$ and PRF $(PRF.Gen, f)$}
  \label{fig:prf}
\end{figure}


\begin{definition}[Computational Indistinguishability] \\
    Let $X = \{X(a,n)\}_{a \in \{0,1\}^*; n \in \mathbb{N}}$ and $Y = \{Y(a,n)\}_{a \in \{0,1\}^*; n \in \mathbb{N}}$ be two probability ensembles, where:
    \begin{itemize}
        \item Each ensemble is an infinite sequence of random variables
        \item $a \in \{0,1\}^*$ represents parties' inputs
        \item $n \in \mathbb{N}$ represents the security parameter
    \end{itemize}
    
    $X$ and $Y$ are said to be computationally indistinguishable, denoted by $X \stackrel{c}{\equiv} Y$, if for every non-uniform polynomial-time algorithm $D$ (called a distinguisher), there exists a negligible function $\mu(\cdot)$ such that for every $a \in \{0,1\}^*$ and every $n \in \mathbb{N}$:
    
    \[ |\Pr[D(X(a,n)) = 1] - \Pr[D(Y(a,n)) = 1]| \leq \mu(n) \]
    
    \end{definition}
    
    \begin{remark}
    This definition captures the idea that no efficient algorithm can tell the difference between samples from $X$ and samples from $Y$ with non-negligible probability. The term "non-uniform" allows the distinguisher $D$ to have hard-coded advice that may depend on the input length, potentially making it more powerful.
    \end{remark}

\begin{definition}[Bilinear map]
    Let $\mathbb{G}_1$, $\mathbb{G}_2$ and $\mathbb{G}_T$ be cyclic groups of prime order $p$, where $\mathbb{G}_1$ and $\mathbb{G}_2$ are multiplicative and $\mathbb{G}_T$ is multiplicative. Let $g$ and $h$ be generators of $\mathbb{G}_1$ and $\mathbb{G}_2$, respectively. We call $e : \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T$ a bilinear map or pairing if it is efficiently computable and the following holds:
    
    \textbf{Bilinearity:} $e(g^a, \tilde{g^b}) = e(g, \tilde{g})^{ab} \quad \forall a,b \in \mathbb{Z}_p$.
    
    \textbf{Non-degeneracy:} $e(g, \tilde{g}) \neq 1_{\mathbb{G}_T}$, i.e., $e(g, \tilde{g})$ generates $\mathbb{G}_T$.
    
   \noindent If $\mathbb{G}_1 = \mathbb{G}_2$, then $e$ is symmetric (Type-1) and asymmetric (Type-2 or 3) otherwise. For Type-2 pairings, there is an efficiently computable isomorphism $\Psi : \mathbb{G}_2 \rightarrow \mathbb{G}_1$ but none from $\mathbb{G}_1 \rightarrow \mathbb{G}_2$; for Type-3 pairings, no efficiently computable isomorphisms between $\mathbb{G}_1$ and $\mathbb{G}_2$ are known. Type-3 pairings are currently the optimal choice in terms of efficiency for a given security level.
\end{definition}

\begin{definition}[Commitment scheme]
    A commitment scheme is a tuple $(\mathsf{Setup}, \mathsf{Commit}, \mathsf{Open})$ of PPT algorithms where:
    
    \begin{itemize}
        \item $\mathsf{Setup}(1^\lambda) \to \mathsf{ck}$ takes security parameter $\lambda$ (in unary) and generates the commitment key $\mathsf{ck}$;
        
        \item $\mathsf{Commit}_{\mathsf{ck}}(m) \to (\cm, r)$ obtains commitment $\cm$ from secret message $m$ and an opening key $r$ which may be the randomness used in the computation.
        
        \item $\mathsf{Open}_{\mathsf{ck}}(\cm; m, r) \to b \in \{0, 1\}$ verifies the opening of the commitment $\cm$ to the message $m$ provided with the opening hint $r$, outputting a decision as to whether $\cm$ commits to $m$. 
    \end{itemize}
\end{definition}

\begin{definition}[Secret Sharing]
    A $(t,n)$ secret sharing scheme $\mathsf{SS}$ is a tuple of $\PPT$ algorithms $(\mathsf{Share}, \mathsf{Combine})$ over message space $x \in X$:
    \begin{itemize}
        \item $\mathsf{Share}^{t,n}(x, r) \torand ([x]_1, \dots, [x]_n)$ takes input $x \in X$, randomness $r$ and outputs $n$ shares $([x]_1, \dots, [x]_n)$
        \item $\mathsf{Combine}^{t,n}([x]_i, \dots, [x]_t) \to x'$ takes a threshold of secret shares $[x]_i$ for $i > t$ as input and combines to form $x'$ the representation of the original message $x' \in X$
    \end{itemize}
\end{definition}

\begin{definition}[Threshold Public-Key Encryption]
A Threshold Public-Key Encryption Scheme $\mathsf{TPK}$ is a set of $\PPT$ algorithms $\mathsf{(KeyGen, Enc, Dec, Verify, Combine)}$ over $\messagespace$: 
    \begin{itemize}
        \item $\mathsf{TPK.Setup}(\secparam, n, t) \torand \{\pk, \vk, (\sk_1, \dots, \sk_n)\}:$ input the $t$ of $n$ threshold, output $\pk$ the public key, $\vk$ the verification key, and $\sk_i$ the shared secret key for each party.
        \item $\mathsf{TPK.Enc}(\pk, m, \rho) \torand \beta:$ input message $m$ and randomness $\rho$, output encryption $\beta$
        \item $\mathsf{TPK.Dec}(\beta, \sk_i)) \to m_i:$ each party decrypts $\beta$ with their shared secret key $\sk_i$
        \item $\mathsf{TPK.Verify}(\pk, \vk , m_i) \to  \bit:$ input $\pk, \vk$ and share of $m_i$, verify $m_i$ was computed correctly from $\pk, \vk$
        \item $\mathsf{TPK.Combine}(\pk, \vk, {m_i}_{i \in \setspace \subseteq [n] s.t. |\setspace| \geq t + 1}) \to m:$ recovers message $m$ given $t + 1$ partial decryptions which verify successfully
    \end{itemize}
\end{definition}


\begin{definition}[Homomorphism]
    Let $G$ and $H$ be groups. A function $\phi: G \to H$ is called a \textit{homomorphism} if it preserves the group operation. Specifically, for any elements $a, b \in G$, the following equation holds:
    
    \[\phi(a \ast b) = \phi(a) \circ \phi(b)\]
    
    where $\ast$ denotes the group operation in $G$ and $\circ$ denotes the group operation in $H$.
    \end{definition}
    
    \begin{remark}
    Note that $\phi$ is not required to be injective (one-to-one) or surjective (onto).
    \end{remark}
    
    \begin{definition}
    For a homomorphism $\phi: G \to H$, the \textit{image} of $\phi$ is defined as:
    
    \[\operatorname{Im}(\phi) = \phi(G) = \{\phi(g) : g \in G\} \subseteq H\]
    \end{definition}

    \begin{definition}[Image of homomorphism]
        For a homomorphism $\phi: G \to H$, the \textit{image} of $\phi$ is defined as:
        
        \[\operatorname{Im}(\phi) = \{h \in H \mid \exists g \in G \text{ such that } \phi(g) = h\}\]
        
        \end{definition}

        \begin{remark}
            The image of a homomorphism $\phi: G \to H$ can be thought of as the "landing spot" in $H$ for elements coming from $G$. It's the subset of $H$ that includes all possible outputs when $\phi$ is applied to any element in $G$. In essence, $\operatorname{Im}(\phi)$ tells us which elements of $H$ are "reachable" through $\phi$ from some element in $G$.
        \end{remark}





\newpage
\subsubsection{Verifiable Random Function}

\subsubsection{Syntax}
\begin{itemize}
    \item $Gen(\secparam) \to (sk, pk):$ samples $s \sample \Zp^*$, sets $sk = s$ and $pk \gets g^s$, returns $(sk, pk)$
    \item $Prove_{sk}(x) \to (y, \pi):$ $y \gets e(g,g)^{1/(x+sk)}$, $\pi \gets g^{1/(x+sk)}$ where $y$ is the $PRF$ output and $\pi$ is the proof of correctness
    \item $Verify_{pk}(x, y, \pi) \to \bit$ to verify $y$ was computed correctly, verify $e(g^x \cdot pk, \pi) = e(g,g)$ and $y = e(g, \pi)$, output 1 for success, 0 for fail
\end{itemize}

\begin{definition}[Verifiable Random Function]

    A PRF is a triplet of $\PPT$ algorithms $(VRF.Gen, VRF.Eval, VRF.Vfy)$ satisfying:
    \begin{enumerate}
        \item Correctness: For any $(pk, sk)$ in the image of $VRF.Gen(\secparam)$ and any $x \in \setX$
        \[
        \begin{aligned}
            (y, \pi) &\gets VRF.Eval_{sk}(x) \\
            1 &\gets VRF.Vfy_{pk}(x, y, \pi)
        \end{aligned}
        \]


    \item Unique Provability: For any $pk$ (not necessarily in the range of $VRF.Gen$, any input $x \in \setX$, pair of outputs $y_0, y_1 \in \setY$ and pair of proofs $\pi_0, \pi_1$ the following holds
    \[
        \begin{aligned}
            1 &\gets VRF.Vfy_{pk}(x,y_0,\pi_0) \\
            1 &\gets VRF.Vfy_{pk}(x,y_1,\pi_1) \\
            y_0 &= y_1
        \end{aligned}
    \]

    \item Pseudorandomness: For any $\PPT$ adversary $\adv$ running the VRF Experiment, there exists a negligible function $\epsilon$ such that 
    \[
         \advantage{}{}[(\adv)] := 
            \left|
        \Pr     \left[ 
                    \mathsf{Exp}^{\mathsf{rnd}}(\adv) \to 1
                \right] - \frac{1}{2}
            \right| \leq \epsilon(\lambda)
    \]
    
    \end{enumerate}

\end{definition}

\begin{figure}
\begin{pchstack}[boxed, center, space=1em]
    \procedure[]{$\mathrm{Exp}^{\mathsf{eval}}(\adv)$}{%
        \text{Sample } b \sample \bit \\
        pk, sk \sample VRF.Gen(1^{\lambda}) \\
        \text{set } x^* = \bot \\
        x^* \gets \adv^{\oracle_{\mathsf{eval}}}(pk) \\
        \pcif x^* \text{was previously queried:} \\
        \t \pcreturn 0 \\
        y_0 \sample \setY \\
        (y_1, \pi) \gets VRF.Eval(pk, x^*) \\
        \adv^{\oracle_{\mathsf{eval}}}(sk, y_b) \to b' \\
        \pcreturn b == b'
    }
    \procedure[]{$\oracle_{\mathsf{eval}(x)}$}{%
        \pcif x \neq x^* \\
        \t (y, \pi) \gets VRF.Eval_{sk}(x) \\
        \t \pcreturn (y, \pi) \\
        \pcelse: \pcreturn \bot \\
    }
\end{pchstack}
  \caption{The pseudorandomness game with adversary $\adv$ and PRF $(PRF.Gen, f)$}
  \label{fig:prf}
\end{figure}



% \newcommand{\vt}{\mathsf{vt}}
% \newcommand{\wx}{\mathsf{wx}}
% \newcommand{\wxone}{\mathsf{w_1x}}
% \newcommand{\wxtwo}{\mathsf{w_2x}}
% \newcommand{\wxhat}{\mathsf{\hat{w}x}}
% % \newcommand{\x}{\mathsf{x}}

% \newcommand{\acu}{\mathsf{ACU}}
% \newcommand{\acusetup}{\mathsf{ACU.Setup}}
% \newcommand{\acuadd}{\mathsf{ACU.Add}}
% \newcommand{\acudel}{\mathsf{ACU.Del}}
% \newcommand{\acuvermem}{\mathsf{ACU.VerMem}}
% \newcommand{\acuvernonmem}{\mathsf{ACU.VerNonMem}}


% \newcommand{\rev}{\mathsf{REV}}
% \newcommand{\revsetup}{\mathsf{REV.Setup}}
% \newcommand{\revrevoke}{\mathsf{REV.Revoke}}
% \newcommand{\revtokengen}{\mathsf{REV.TokenGen}}
% \newcommand{\revtokenver}{\mathsf{REV.TokenVer}}

% \newcommand{\rt}{\mathsf{rt}}

\subsection{Revocation}
Credential revocation is a fundamental challenge in identity management systems. While credentials grant users access to services, there must be mechanisms to invalidate them when necessary. Since the introduction of public key infrastructure, numerous solutions have been proposed to handle certificate revocation such as time-based expiration, usage limits (k-times use), and revocation lists. In the latter approach, a trusted authority manages a whitelist of valid credentials or blacklist of revoked ones, requiring users to prove their credential status with respect to the list.

The challenge becomes more complex in privacy-preserving systems as users must be able to prove revocation status without revealing the credential or its attributes. Furthermore, the revocation list should not leak information about which credentials are valid or revoked. 

\subsubsection{Revocation Scheme}
A revocation scheme enables efficient proofs of credential validity while maintaining privacy of the revocation status. The scheme consists of a revocation authority that manages the revocation state, protocols for revoking credentials, and methods for users to prove their credentials remain valid. A privacy-preserving revocation scheme must satisfy several properties:

\begin{itemize}
    \item Privacy: Users can prove their credential's status without revealing the credential
    \item Unlinkability: Multiple proofs by the same user cannot be linked
    \item Efficiency: Proofs should be succinct and verification efficient
    \item Dynamic Updates: The system supports real-time credential revocation
\end{itemize}

\paragraph{Syntax}
A revocation scheme consists of the following algorithms:

\begin{itemize}
    \item $\revsetup(\secparam) \torand (\ppar, \sk, \pk, \vt):$ Given security parameter $\secparam$, generates system parameters $\ppar$, authority's secret key $\sk$, public key $\pk$, and initial revocation state $\vt$
    
    \item $\revrevoke(\sk, \vt, \cred) \to (\vt', \text{RI}):$ Revokes credential $\cred$, updates revocation state from $\vt$ to $\vt'$, and outputs revocation information RI
    
    \item $\revtokengen(\cred, \vt, \text{RI}) \to \rt:$ Generates a revocation token $\rt$ for credential $\cred$ using the current revocation state $\vt$ and revocation information RI
    
    \item $\revtokenver(\vt, \cred, \rt) \to \bit:$ Verifies revocation token $\rt$ for credential $\cred$ against revocation state $\vt$
\end{itemize}

\subsubsection{Accumulator}
An accumulator allows for compact representation of a set while enabling efficient proofs of membership. Our construction uses a universal accumulator that supports both membership and non-membership proofs. The accumulator maintains a constant-size value regardless of the number of elements in the set, while allowing elements to be dynamically added and removed. For each element, the system can generate succinct witnesses that prove either membership or non-membership in the accumulated set.

\subsubsection{Syntax}
An accumulator $\acu$ is a set of $\PPT$ algorithms $\acu = \mathsf{Setup, Add, Del, VerMem, VerNonMem}$. 
\begin{itemize}
    \item $\acusetup(\secparam) \torand \ppar, \sk, \pk, \vt:$ generates system parameters, takes security parameter $\secparam$ as input, outputs system parameters $\ppar$, secret key $\sk$, public key $\pk$, and initial accumulator value $\vt$
    
    \item $\acuadd(\sk, \vt, \x) \to (\vt', \wx):$ adds element $\x$, takes secret key $\sk$, current accumulator value $\vt$, element $\x$ as input. Outputs updated accumulator value $\vt'$, and membership witness $\wx$
    
    \item $\acudel(\sk, \vt, \x) \to (\vt', \wxhat):$ Deletes element $\x$, takes secret key $\sk$, current accumulator value $\vt$, element $\x$ as input. Outputs updated accumulator value $\vt'$, non-membership witness $\wxhat$ 
    
    \item $\acuvermem(\vt, \x, \wx) \to \bit:$ verifies membership, takes current accumulator value $\vt$, element $\x$, witness $\wx$ as input. Outputs accept/reject
    
    \item $\acuvernonmem(\vt, \x, \wxhat) \to \bit:$ Verifies non-membership, takes current accumulator value $\vt$, element $\x$, non-member witness $\wxhat$ as input. Outputs accept/reject
\end{itemize}

 with additional witness operations $\mathsf{MemWitUpOnAdd/Del, NonMemWitUpOnAdd/Del}$ 


 \subsection{Discussion}
 
The Internet Identity Workshop discussed a problem space summarised by the following problems:
\begin{enumerate}
    \item issuing credentials that are both government and privately issued
    \item retaining accountability in derived credentials, ensuring derived credentials are fit for purpose and have revocation (Proveable Provenance, Linked Data)
    \item combining traditional digital identity with decentralized identity
\end{enumerate}

A user has an Identity linked to multiple credentials, such as a driver's license and university card. Users want to authenticate with various Relying Parties (Verifiers) without being linked between multiple uses of the same service (e.g. a user verifying multiple credentials with 1 service such as a bank requiring proof of multiple credentials linked to an identity), and between uses of different services (e.g. a user presenting their drivers license for age verification on multiple services).

Current decentralized identity systems either don't provide this functionality or provide it at the expense of either accountability or privacy. CanDID stores a map between users multi-layered credentials providing a solution to the problem at the expense of the user's privacy. Other credential systems and pseudonym systems prove equality of hidden attributes in a credential such as name or id, which can more-easily be forged and does not support the hierarchical structure leveraging a highly secure and accountable government identity with not-so secure private credentials.


\noindent \textbf{Credential Chaining}


\noindent \textbf{Pseudonym Systems}
There are 2 main models for Pseudonyms. One where the user has a Master Credential and derives pseudonym, or context credentials from the Master Credential. The applications differ; for example, in \textbf{Model 1}, a user may have their Passport as their Master Credential and wish to use it in a different scenario, such as voting for an election. The user will derive, by themselves, a new credential with the context "voting-2024," which will be verified in the same way as the master credential.
\textbf{Model 2} differs in application scenarios. A context credential represents a credential from a different issuer, for example, a driver's license. During Context Credential issuance, a user will present their Master Credential which will be used to verify the identity of a user and to link the 2 credentials together. During context credential verification, the user may be requested to present just their Context Credential, or perhaps in a high-security verification setting, where a user may need to prove attributes in multiple credentials both Master and Context will need to be presented together. We optimize for this setting while \emph{preserving privacy.}



\noindent \textbf{Pseudonym Model 1: Master Credential, One Issuer, derived Pseudonyms}

SyRA and TACT optimize for Non-Interactivity
They also define context differently to us. Which isn't what CanDID defines context as and doesn't work for the same usescases and CanDID was defined for. 

Previous Methods

\noindent SyRA: Sybil-Resilient Anonymous Signatures  with Applications to Decentralized Identity \cite{crites_syra_2024}
1. enables users to "derive" unlinkable, sybil resistant pseudonyms (signatures) for a context e.g. PRF(sk, ctx) without interacting with the issuer
2. does not store a mapping on the issuer
3. Security properties: Sybil resistance in the context. Anonymity: no information is leaked through their nyms or signatures. Proves UC security for unforgeability, Sybil resilience, privacy, and unlinkability
4. SyRA leaves support for Identity Attributes for future work.

Summary: First, a protocol with issuer creates a user with secret key $s$. $s$ generates a context specific pseudonym, or tag $T$ "that attaches itself to a signature"?

\begin{itemize}
    \item Level 1: $Issue_{isk}(s)$: $VRF_{isk}(s) \to T, \pi_{prf}$ such that $\pi_{prf}$ generates the users keys and is symmetric across $\G_1, \G_2$: This algorithm is computed by the issuer with their secret key $isk$ on identity string $s$ Outputs $T = e(g, \tilde{g})^{1/(s + isk)}$ and $\pi_{prf}$ is $usk = g^{1/(s + isk)} \in \G_1$ and $\widehat{usk} = \tilde{g}^{1/(s + isk)} \in \G_2$. Their verify algorithm is the same as the Dodis Yampolskiy and also verifies the asymmetric keys with bilinear pairing.
    \item Level 2: $Sign_{usk, \widehat{usk}}(ctx, m, ivk)$: $VUF_{usk}(ctx) \to T = e(H(ctx), \widehat{usk})$: This is the "sybil resistant signature". Proof of correctness comes from sigma protocol. During the verify protocol, the 
\end{itemize}

Conclusion: SyRA creates a signature scheme where a user can "sign" on $ctx, m$ from their secret key based on a VRF of their identity and the issuer's key. This does not account for Attribute-based credentials.

Attribute-Based Threshold Issuance Anonymous Counting Tokens \cite{rabaninejad_attribute-based_nodate}
What don't they do that we do?
We avoid Groth Sahai proofs - page 26 they refer to proving the signature scheme with GS proofs. 
They use Naor Pinkas Reingold PRF and verify signature with GS proofs. 
They focus only on deriving credentials / pseudonyms from their

\noindent \textbf{Pseudonym Model 2: Master Credential, Multiple Issuers, Different Pseudonyms}
The Pseudonym Model \cite{goos_pseudonym_2000} presents as an interaction between a User, a Certificate Authority (CA), and a Pseudonym Organisation (O). The user's identity is registered to the CA with their keypair $skU, pkU$, receiving a Master Credential to act as a trust anchor for all pseudonyms. With their Master Credential, Users request \emph{unlinkable} Pseudonyms for other organizations by first proving the knowledge of a Master Credential that verifies with the CA, and the pseudonym requested has the same keypair as the Master Credential. Organizations \emph{blindly} issue Pseudonym credentials on the same keypair as the Master Credential.


\begin{itemize}
    \item \textbf{$MasterCredIssue(skU, pkU, identity, skCA) \to CredM$} is an interactive algorithm run by a user and a credential authority with keypair $skCA, pkCA$. The user is known to the CA and shares their identity and a keypair $skU, pkU$. The $CA$ checks the $skU, pkU$ relation and issues $CredM$, a signature $\sigma_{CA} \gets Sign_{skCA}(pkU)$
    
    \item \textbf{$NymGeneration(CredM, pkCA, Nym, skO) \to CredNym$} is an interactive algorithm run by a user and an organization the user wishes to create a pseudonym with. 
    $Nym1$ is a commitment $Com(skU, pkU, r)$ with randomness $r$, $r$ should be unique per pseudonym. 
    $U$ generates a zero-knowledge proof of knowledge of a new pseudonym $Nym1$ with $skU, pkU$ corresponding to $CredM$, $CredM$ verifies correctly, and $pkU, skU$ are related. 
    \[
    \begin{aligned}
    ZKP
    \{ 
        (skU, pkU, r): Nym &= Com(skU, pkU, r) \; \wedge \\
        Verify_{pkCA}(CredM) &= 1 \; \wedge \\ 
        pkU &= g^{skU}
     \}
    \end{aligned}
    \]
    On successful ZKP verification, algorithm outputs $CredNym \gets Sign_{skO}(Nym)$

    \item \textbf{$NymVerify(CredNym, pkO) \to \bit $} is an interactive algorithm run by a user and a verifier. Recall $CredNym$ is a signature over a commitment $Sign_{skO}(Nym)$. The user randomizes $CredNym' \gets CredNym$ and $Nym' \gets Com(skU, pkU, r)$, and in zero knowledge, proves $CredNym$ verifies correctly with respect to the original signature, and the organisation public key
        \[
        \begin{aligned}
        ZKP
        \{  
            (skU, pkU, r, r'): Nym' &= Com(skU, pkU, r') \; \wedge \\
            \exists \; Nym \text{ such that } Verify_{pkO}(Nym) &= 1 \; \wedge \\ 
            Nym &= Com(skU, pkU, r) \; \wedge \\
            pkU &= g^{skU}
        \}
        \end{aligned}
        \]
\end{itemize}




\newpage
\subsection{NIZK for Sybil Resistant Issuance}
We have $g^{\frac{1}{m}}$ and $g^m$. We want to prove their relationship is reciprocal. We will use this later when proving the output of the Dodis Yampolskiy VRF $g^{\frac{1}{sk + x}}$
Let $m_1 = m$, and $m_2 = \frac{1}{m}$. Therefore, we can prove that $m_1 \cdot m_2 = 1$ 
\[ 
    \begin{aligned}
        C_1 &= g^{m_1}h^{r_1} \\
        C_2 &= g^{m_2}h^{r_2} \\
        C_3 &= C_1^{m_2}h^{r_3} \\ 
        C_4 &= h^{r_1m_2 + r_3} \\ 
    \end{aligned}
\]

We use $C_1, C_2$ in a zero-knowledge proof protocol to prove the relation with public elements $C_1, C_2, g, h$

\[
ZKP
    \left\{ 
    (m_1, m_2, r_1, r_2): C_1 = g^{m_1}h^{r_1} \wedge C_2 = g^{m_2}h^{r_2} \wedge m_1 \cdot m_2 = 1
    \right\}
\]

\pcb{
\prover[m_1, m_2, r_1, r_2] \< \< \verifier[C_1, C_2, g, h]  \\[0.1\baselineskip][\hline]
\<\< \\[-0.5\baselineskip]
\pclinecomment{$C_1 = g^{m_1}h^{r_1}, C_2 = g^{m_2}h^{r_2}$} \\
{\{\rho_i\}_{i=1}^4, \{\beta_i\}_{i=1}^2}  \sample \mathbb{Z}_q^6 \<\< \\
T_1 \gets g^{\beta_1}h^{\rho_1} \<\< \\
T_2 \gets g^{\beta_2}h^{\rho_2} \<\< \\
\pclinecomment{generate interim elements} \\
C_3 \gets C_1^{m_2}h^{r_3} \<\< \\
T_3 \gets C_1^{\beta_2}h^{\rho_3} \<\< \\
r_4 \gets r_1m_2 + r_3 \<\<  \\
C_4 \gets h^{r4} \<\< \\
T_4 \gets h^{\rho_4} \<\< \\
\< \sendmessageright* {\{C_i, T_i\}_{i=1}^4} \< \\
\< \sendmessageleft*{e} \< e \sample \mathbb{Z}_q \\
z_{m1} = \beta_1 + e \cdot m_1 \<\< \\
z_{r1} = \rho_1 + e \cdot r_1 \<\< \\
z_{m2} = \beta_2 + e \cdot m_2 \<\< \\
z_{r2} = \rho_2 + e \cdot r_2 \<\< \\
z_{r3} = \rho_3 + e \cdot r_3 \<\< \\
z_{r4} = \rho_4 + e \cdot r_4 \<\< \\
\< \sendmessageright*{\{z_{mi}\}_{i=1}^2, \{z_{ri}\}_{i=1}^4 } \< \\
\<\< C_1^e \cdot T_1 \stackrel{?}{=} g^{z_{m1}} h^{z_{r1}}\\
\<\< C_2^e \cdot T_2 \stackrel{?}{=}  g^{z_{m2}} h^{z_{r2}}\\
\<\< C_3^e \cdot T_3 \stackrel{?}{=}  C_1^{z_{m2}} h^{z_{r3}}\\
\<\< C_4^e \cdot T_4 \stackrel{?}{=}  h^{z_{r4}}\\
\<\< C_3/C_4 = g \\
}